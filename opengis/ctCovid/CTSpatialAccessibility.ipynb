{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as osmnx\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "import folium, itertools, os, time, warnings\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DERRICK: change to CT overy fifty by tracts\n",
    "pop_data = gpd.read_file('./CTData/PopData/csTracts.shp')\n",
    "pop_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Covid Town Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DERRICK: change to CT covid by town\n",
    "pop_data = gpd.read_file('./CTData/PopData/covidTown.shp')\n",
    "pop_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Data\n",
    "\n",
    "Note that 999 is treated as a \"NULL\"/\"NA\" so these hospitals are filtered out. This data contains the number of ICU beds and ventilators at each hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DERRICK: change to CT hospitals\n",
    "hospitals = gpd.read_file('./CTData/HospitalData/hospitals.shp')\n",
    "hospitals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Hospital Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DERRICK: switch lat long to CT, bring out starting zoom a bit\n",
    "m = folium.Map(location=[41.5, -72.65], tiles='cartodbpositron', zoom_start=8.47)\n",
    "for i in range(0, len(hospitals)):\n",
    "    folium.CircleMarker(\n",
    "    # DERRICK: add CT data, edit lat long and pop ups\n",
    "      location=[hospitals.iloc[i]['LATITUDE'], hospitals.iloc[i]['LONGITUDE']],\n",
    "      # getting error tuple index out of range\n",
    "      # popup=\"{}{}\\n{}{}\\n{}{}\".format('Hospital Name: ',hospitals.iloc[i]['NAME']),\n",
    "                                      #'Beds: ',hospitals.iloc[i]['BEDS']),\n",
    "      radius=5,\n",
    "      color='grey',\n",
    "      fill=True,\n",
    "      fill_opacity=0.6,\n",
    "      legend_name = 'Hospitals'\n",
    "    ).add_to(m)\n",
    "legend_html =   '''<div style=\"position: fixed; width: 20%; heigh: auto;\n",
    "                            bottom: 10px; left: 10px;\n",
    "                            solid grey; z-index:9999; font-size:14px;\n",
    "                            \">&nbsp; Legend<br>'''\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CT Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to CT grid file\n",
    "grid_file = gpd.read_file('./CTData/GridFile/ctGrid.shp')\n",
    "grid_file.plot(figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CT Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DERRICK: change to CT\n",
    "#if not os.path.exists(\"CTData/Connecticut_Network.graphml\"):\n",
    "   # G = osmnx.graph_from_place('Connecticut', network_type='drive') # pulling the drive network the first time will take a while\n",
    "   # osmnx.save_graphml(G, 'Connecticut_Network.graphml', folder=\"CTData\")\n",
    "#else:\n",
    "    #G = osmnx.load_graphml('Connecticut_Network.graphml', folder=\"CTData\", node_type=str)\n",
    "#osmnx.plot_graph(G, fig_height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CT Buffered Network (to get roads in out of state hospitals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ct_buff = gpd.read_file('./CTData/NetworkShp/bufferPrj.shp')\n",
    "if not os.path.exists(\"CTData/CT_Buffered_Network.graphml\"):\n",
    "    G = osmnx.graph_from_place('Connecticut', buffer_dist=15000, network_type='drive')\n",
    "    #G = ox.graph_from_bbox(-73.9054017748721,-71.60720220301667,40.8812594400134,42.18560758357975, network_type='drive')\n",
    "    #G = osmnx.graph_from_polygon(ct_buff, network_type='drive') # pulling the drive network the first time will take a while\n",
    "    osmnx.save_graphml(G, 'CT_Buffered_Network.graphml', folder=\"CTData\")\n",
    "else:\n",
    "    G = osmnx.load_graphml('CT_Buffered_Network.graphml', folder=\"CTData\", node_type=str)\n",
    "osmnx.plot_graph(G, fig_height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def network_setting(network):\n",
    "    _nodes_removed = len([n for (n, deg) in network.out_degree() if deg ==0])   #remove 0 outdegree nodes \n",
    "    network.remove_nodes_from([n for (n, deg) in network.out_degree() if deg ==0])\n",
    "    for component in list(nx.strongly_connected_components(network)):   #remove small networks\n",
    "        if len(component)<10:\n",
    "            for node in component:\n",
    "                _nodes_removed+=1\n",
    "                network.remove_node(node)\n",
    "    for u, v, k, data in tqdm(G.edges(data=True, keys=True),position=0):  #DERRICK: a bit confused about u, v, k\n",
    "        if 'maxspeed' in data.keys():\n",
    "            speed_type = type(data['maxspeed'])\n",
    "            if (speed_type==str):\n",
    "                if len(data['maxspeed'].split(','))==2:\n",
    "                    data['maxspeed']=float(data['maxspeed'].split(',')[0])                  \n",
    "                elif data['maxspeed']=='signals':\n",
    "                    data['maxspeed']=35.0 # drive speed setting as 35 miles\n",
    "                else:\n",
    "                    data['maxspeed']=float(data['maxspeed'].split()[0])\n",
    "            else:\n",
    "                data['maxspeed']=float(data['maxspeed'][0].split()[0])\n",
    "        else:\n",
    "            data['maxspeed']= 35.0 #miles\n",
    "        data['maxspeed_meters'] = data['maxspeed']*26.8223 # convert mile to meter\n",
    "        data['time'] = float(data['length'])/ data['maxspeed_meters']\n",
    "    print(\"Removed {} nodes ({:2.4f}%) from the OSMNX network\".format(_nodes_removed, _nodes_removed/float(network.number_of_nodes())))\n",
    "    print(\"Number of nodes: {}\".format(network.number_of_nodes()))\n",
    "    print(\"Number of edges: {}\".format(network.number_of_edges()))\n",
    "    return(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Helper\" Functions\n",
    "\n",
    "The functions below are needed for our analysis later, let's take a look!\n",
    "\n",
    "### network_setting\n",
    "\n",
    "Cleans the OSMNX network to work better with drive-time analysis.\n",
    "\n",
    "First, we remove all nodes with 0 outdegree because any hospital assigned to such a node would be unreachable from everywhere. Next, we remove small (under 10 node) *strongly connected components* to reduce erroneously small ego-centric networks. Lastly, we ensure that the max speed is set and in the correct units before calculating time.\n",
    "\n",
    "Args:\n",
    "\n",
    "* network: OSMNX network for the spatial extent of interest\n",
    "\n",
    "Returns:\n",
    "\n",
    "* OSMNX network: cleaned OSMNX network for the spatial extent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hospital_setting\n",
    "\n",
    "Finds the nearest OSMNX node for each hospital.\n",
    "\n",
    "Args:\n",
    "\n",
    "* hospital: GeoDataFrame of hospitals\n",
    "* G: OSMNX network\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame of hospitals with info on nearest OSMNX node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def hospital_setting(hospitals, G):\n",
    "    hospitals['nearest_osm']=None\n",
    "    for i in tqdm(hospitals.index, desc=\"Find the nearest osm from hospitals\", position=0):   #loo\n",
    "        hospitals['nearest_osm'][i] = osmnx.get_nearest_node(G, [hospitals['LATITUDE'][i], hospitals['LONGITUDE'][i]], method='euclidean') # find the nearest node from hospital location\n",
    "    print ('hospital setting is done')\n",
    "    return(hospitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pop_centroid\n",
    "\n",
    "Converts geodata to centroids\n",
    "\n",
    "Args:\n",
    "\n",
    "* pop_data: a GeodataFrame\n",
    "* pop_type: a string, either \"pop\" for general population or \"covid\" for COVID-19 case data\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame of centroids with population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to estimate the centroids of census tract / county\n",
    "def pop_centroid (pop_data, pop_type):\n",
    "    pop_data = pop_data.to_crs({'init': 'epsg:4326'})\n",
    "    if pop_type ==\"pop\":\n",
    "        pop_data=pop_data[pop_data['OverFifty']>=0] \n",
    "    if pop_type ==\"covid\":\n",
    "        # DERRICK: change 'cases' to 'Cases'\n",
    "        pop_data=pop_data[pop_data['Cases']>=0]\n",
    "    pop_cent = pop_data.centroid # it make the polygon to the point without any other information\n",
    "    pop_centroid = gpd.GeoDataFrame()\n",
    "    i = 0\n",
    "    for point in tqdm(pop_cent, desc='Pop Centroid File Setting', position=0):\n",
    "        if pop_type== \"pop\":\n",
    "            pop = pop_data.iloc[i]['OverFifty']\n",
    "            # believe 'GEOID' will work\n",
    "            code = pop_data.iloc[i]['GEOID']\n",
    "        if pop_type ==\"covid\":\n",
    "            pop = pop_data.iloc[i]['Cases']\n",
    "            # change ZCTA5CE10 to objectid\n",
    "            code = pop_data.iloc[i].OBJECTID\n",
    "        pop_centroid = pop_centroid.append({'code':code,'pop': pop,'geometry': point}, ignore_index=True)\n",
    "        i = i+1\n",
    "        #JOE: somehow this code loses the CRS metadata in conversion to centroids\n",
    "    pop_centroid.crs = \"epsg:4326\"\n",
    "    return(pop_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate_catchment_area\n",
    "\n",
    "Calculates a catchment area of things within some distance of a point using a given metric.\n",
    "\n",
    "Function first creates an ego-centric subgraph on the NetworkX road network starting with the nearest OSM node for the hospital and going out to a given distance as measured by the distance unit. We then calculate the convex hull around the nodes in the ego-centric subgraph and make it a GeoPandas object.\n",
    "\n",
    "Args:\n",
    "\n",
    "* G: OSMNX network\n",
    "* nearest_osm: OSMNX road network node that is closest to the place of interest (hospital)\n",
    "* distance: the max distance to include in the catchment area\n",
    "* distance_unit: how we measure distance (used by ego_graph), we always use time\n",
    "\n",
    "Returns:\n",
    "\n",
    "* GeoDataFrame the catchment area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def calculate_catchment_area(G, nearest_osm, distance, distance_unit = \"time\"):\n",
    "    road_network = nx.ego_graph(G, nearest_osm, distance, distance=distance_unit) \n",
    "    nodes = [Point((data['x'], data['y'])) for node, data in road_network.nodes(data=True)]\n",
    "    polygon = gpd.GeoSeries(nodes).unary_union.convex_hull ## to create convex hull\n",
    "    #JOE: Interesting: convex hull may not be the best solution. Maybe a buffer clipped by the convex hull?\n",
    "    polygon = gpd.GeoDataFrame(gpd.GeoSeries(polygon)) ## change polygon to geopandas\n",
    "    polygon = polygon.rename(columns={0:'geometry'}).set_geometry('geometry')\n",
    "    return polygon.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hospital_measure_acc\n",
    "\n",
    "Measures the effect of a single hospital on the surrounding area. (Uses `calculate_catchment_area`)\n",
    "\n",
    "Args:\n",
    "\n",
    "* \\_thread\\_id: int used to keep track of which thread this is\n",
    "* hospital: Geopandas dataframe with information on a hospital\n",
    "* pop_data: Geopandas dataframe with population data\n",
    "* distances: Distances in time to calculate accessibility for\n",
    "* weights: how to weight the different travel distances\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Tuple containing:\n",
    "    * Int (\\_thread\\_id)\n",
    "    * GeoDataFrame of catchment areas with key stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospital_measure_acc (_thread_id, hospital, pop_data, distances, weights):\n",
    "    ##distance weight = 1, 0.68, 0.22\n",
    "    polygons = []\n",
    "    for distance in distances:\n",
    "        polygons.append(calculate_catchment_area(G, hospital['nearest_osm'],distance))\n",
    "    for i in range(1, len(distances)):\n",
    "        polygons[i] = gpd.overlay(polygons[i], polygons[i-1], how=\"difference\")\n",
    "        \n",
    "    num_pops = []\n",
    "    for j in pop_data.index:\n",
    "        point = pop_data['geometry'][j]\n",
    "        for k in range(len(polygons)):\n",
    "            if len(polygons[i]) > 0: # to exclude the weirdo (convex hull is not polygon)\n",
    "                if (point.within(polygons[k].iloc[0][\"geometry\"])):\n",
    "                    num_pops.append(pop_data['pop'][j]*weights[k])  \n",
    "    total_pop = sum(num_pops)\n",
    "    for i in range(len(distances)):\n",
    "        polygons[i]['time']=distances[i]\n",
    "        polygons[i]['total_pop']=total_pop\n",
    "        # DERRICK: add 'BEDS'\n",
    "        polygons[i]['hospital_beds'] = float(hospital['BEDS'])/polygons[i]['total_pop'] # proportion of # of beds over pops in 10 mins\n",
    "        polygons[i]['hospital_ICU'] = float(hospital['ICU'])/polygons[i]['total_pop'] # proportion of # of beds over pops in 10 mins\n",
    "        polygons[i].crs = { 'init' : 'epsg:4326'}\n",
    "        # change UTM zone from 16N 'epsg:32616' to zone 18n 'epsg:32618'\n",
    "        polygons[i] = polygons[i].to_crs({'init':'epsg:32618'})\n",
    "    print('\\rCatchment for hospital {:4.0f} complete'.format(_thread_id), end=\"\")\n",
    "    return(_thread_id, [ polygon.copy(deep=True) for polygon in polygons ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure_acc_par\n",
    "\n",
    "Parallel implementation of accessibility measurement.\n",
    "\n",
    "Args:\n",
    "\n",
    "* hospitals: Geodataframe of hospitals\n",
    "* pop_data: Geodataframe containing population data\n",
    "* network: OSMNX street network\n",
    "* distances: list of distances to calculate catchments for\n",
    "* weights: list of floats to apply to different catchments\n",
    "* num\\_proc: number of processors to use.\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Geodataframe of catchments with accessibility statistics calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def hospital_acc_unpacker(args):\n",
    "    return hospital_measure_acc(*args)\n",
    "\n",
    "#JOE: Add code here to record start time, end time, duration, number of processes... \n",
    "# DERRICK: accomplished by printing time where the functions are implemented\n",
    "def measure_acc_par (hospitals, pop_data, network, distances, weights, num_proc = 4):\n",
    "    catchments = []\n",
    "    for distance in distances:\n",
    "        catchments.append(gpd.GeoDataFrame())\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    hospital_list = [ hospitals.iloc[i] for i in range(len(hospitals)) ]\n",
    "    results = pool.map(hospital_acc_unpacker, zip(range(len(hospital_list)), hospital_list, itertools.repeat(pop_data), itertools.repeat(distances), itertools.repeat(weights)))\n",
    "    pool.close()\n",
    "    results.sort()\n",
    "    results = [ r[1] for r in results ]\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(distances)):\n",
    "            catchments[j] = catchments[j].append(results[i][j], sort=False)\n",
    "    return catchments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overlap_calc\n",
    "\n",
    "Calculates and aggregates accessibility statistics for one catchment on our grid file.\n",
    "\n",
    "Args:\n",
    "\n",
    "* \\_id: thread ID\n",
    "* poly: GeoDataFrame representing a catchment area\n",
    "* grid_file: a GeoDataFrame representing our grids\n",
    "* weight: the weight to applied for a given catchment\n",
    "* service_type: the service we are calculating for: ICU beds or ventilators\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Tuple containing:\n",
    "    * thread ID\n",
    "    * Counter object (dictionary for numbers) with aggregated stats by grid ID number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "from collections import Counter\n",
    "def overlap_calc(_id, poly, grid_file, weight, service_type):\n",
    "    value_dict = Counter()\n",
    "    if type(poly.iloc[0][service_type])!=type(None):           \n",
    "        value = float(poly[service_type])*weight\n",
    "        intersect = gpd.overlay(grid_file, poly, how='intersection')\n",
    "        intersect['overlapped']= intersect.area\n",
    "        intersect['percent'] = intersect['overlapped']/intersect['area']\n",
    "        intersect=intersect[intersect['percent']>=0.5]\n",
    "        intersect_region = intersect['id']\n",
    "        for intersect_id in intersect_region:\n",
    "            try:\n",
    "                value_dict[intersect_id] +=value\n",
    "            except:\n",
    "                value_dict[intersect_id] = value\n",
    "    return(_id, value_dict)\n",
    "\n",
    "def overlap_calc_unpacker(args):\n",
    "    return overlap_calc(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overlapping_function\n",
    "\n",
    "Calculates how all catchment areas overlap with and affect the accessibility of each grid in our grid file.\n",
    "\n",
    "Args:\n",
    "\n",
    "* grid_file: GeoDataFrame of our grid\n",
    "* catchments: GeoDataFrame of our catchments\n",
    "* service_type: the kind of care being provided (ICU beds vs. ventilators)\n",
    "* weights: the weight to apply to each service type\n",
    "* num\\_proc: the number of processors\n",
    "\n",
    "Returns:\n",
    "\n",
    "* Geodataframe - grid\\_file with calculated stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def overlapping_function (grid_file, catchments, service_type, weights, num_proc = 4):\n",
    "    grid_file[service_type]=0\n",
    "    pool = mp.Pool(processes = num_proc)\n",
    "    acc_list = []\n",
    "    for i in range(len(catchments)):\n",
    "        acc_list.extend([ catchments[i][j:j+1] for j in range(len(catchments[i])) ])\n",
    "    acc_weights = []\n",
    "    for i in range(len(catchments)):\n",
    "        acc_weights.extend( [weights[i]]*len(catchments[i]) )\n",
    "    results = pool.map(overlap_calc_unpacker, zip(range(len(acc_list)), acc_list, itertools.repeat(grid_file), acc_weights, itertools.repeat(service_type)))\n",
    "    pool.close()\n",
    "    results.sort()\n",
    "    results = [ r[1] for r in results ]\n",
    "    service_values = results[0]\n",
    "    for result in results[1:]:\n",
    "        service_values+=result\n",
    "    for intersect_id, value in service_values.items():\n",
    "        grid_file.loc[grid_file['id']==intersect_id, service_type] += value\n",
    "    return(grid_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization\n",
    "\n",
    "Normalizes our result (Geodataframe) for a given resource (res)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no change\n",
    "def normalization (result, res):\n",
    "    result[res]=(result[res]-min(result[res]))/(max(result[res])-min(result[res]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# file_import\n",
    "\n",
    "Imports all files we need to run our code and pulls the Illinois network from OSMNX if it is not present (will take a while). \n",
    "\n",
    "**NOTE:** even if we calculate accessibility for just Chicago, we want to use the Illinois network (or at least we should not use the Chicago network) because using the Chicago network will result in hospitals near but outside of Chicago having an infinite distance (unreachable because roads do not extend past Chicago).\n",
    "\n",
    "Args:\n",
    "\n",
    "* pop_type: population type, either \"pop\" for general population or \"covid\" for COVID-19 cases\n",
    "* region: the region to use for our hospital and grid file (\"Chicago\" or \"Illinois\")\n",
    "\n",
    "Returns:\n",
    "\n",
    "* G: OSMNX network\n",
    "* hospitals: Geodataframe of hospitals\n",
    "* grid_file: Geodataframe of grids\n",
    "* pop_data: Geodataframe of population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_import (pop_type, region):\n",
    "    # DERRICK: change to CT and change file path to CTDAta\n",
    "    if not os.path.exists(\"CTData/CT_Buffered_Network.graphml\"):\n",
    "        G = osmnx.graph_from_place('Connecticut', network_type='drive') # pulling the drive network the first time will take a while\n",
    "        osmnx.save_graphml(G, 'CT_Buffered_Network.graphml', folder=\"CTData\")\n",
    "    else:\n",
    "        G = osmnx.load_graphml('CT_Buffered_Network.graphml', folder=\"CTData\", node_type=str)\n",
    "    # change to CT Hospitals\n",
    "    hospitals = gpd.read_file('./CTData/HospitalData/hospitals.shp'.format(region))\n",
    "    # change to ctGrid -- possibility for later -- to make scalable grids basde on hospital regions\n",
    "    grid_file = gpd.read_file('./CTData/GridFile/ctGrid.shp'.format(region))\n",
    "    if pop_type==\"pop\":\n",
    "        pop_data = gpd.read_file('./CTData/PopData/csTracts.shp'.format(region))\n",
    "    if pop_type==\"covid\":\n",
    "        pop_data = gpd.read_file('./CTData/PopData/covidTown.shp'.format(region))\n",
    "    return G, hospitals, grid_file, pop_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_map(output_grid, base_map, hospitals, resource):\n",
    "    ax=output_grid.plot(column=resource, cmap='Blues',figsize=(18,12), legend=True, zorder=1)\n",
    "    base_map.plot(ax=ax, facecolor=\"none\", edgecolor='gray', lw=0.1)\n",
    "    #ax.scatter(hospitals.LONGITUDE, hospitals.LATITUDE, zorder=1, c='black', s=8)\n",
    "    hospitals.plot(ax=ax, markersize=10, zorder=1, c='red')\n",
    "    #JOE: changed code to plot hospitals with geometry rather than X and Y attributes, so that points may be projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "Below you can customize the input of the model:\n",
    "\n",
    "* Processor - the number of processors to use\n",
    "* Region - the spatial extent of the measure\n",
    "* Population - the population to calculate the measure for\n",
    "* Resource - the hospital resource of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "processor_dropdown = ipywidgets.Dropdown( options=[(\"1\", 1), (\"2\", 2), (\"3\", 3), (\"4\", 4)],\n",
    "    value = 1, description = \"Processor: \")\n",
    "\n",
    "place_dropdown = ipywidgets.Dropdown( options=[(\"Connecticut\", \"Connecticut\")],\n",
    "    value = \"Connecticut\", description = \"Region: \")\n",
    "\n",
    "population_dropdown = ipywidgets.Dropdown( options=[(\"Population at Risk\", \"pop\"), (\"COVID-19 Patients\", \"covid\") ],\n",
    "    value = \"pop\", description = \"Population: \")\n",
    "\n",
    "resource_dropdown = ipywidgets.Dropdown( options=[(\"All Beds\", \"hospital_beds\"), (\"ICU Beds\", \"hospital_ICU\")],\n",
    "    value = \"hospital_beds\", description = \"Resource: \")\n",
    "display(processor_dropdown,place_dropdown,population_dropdown,resource_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, hospitals, grid_file, pop_data = file_import (population_dropdown.value, place_dropdown.value)\n",
    "G = network_setting (G)\n",
    "pop_data = pop_centroid(pop_data, population_dropdown.value)\n",
    "hospitals = hospital_setting(hospitals, G)\n",
    "distances=[10,20,30] # distances in travel time\n",
    "weights=[1.0, 0.68, 0.22] # weights where weights[0] is applied to distances[0]\n",
    "resources = [\"hospital_beds\", \"hospital_ICU\"] # resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DERRICK: Add Code to PRINT processing time \n",
    "start_time = time.time()\n",
    "catchments = measure_acc_par(hospitals, pop_data, G, distances, weights, num_proc=processor_dropdown.value)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DERRICK: Add Code to PRINT processing time (seems)\n",
    "start_time = time.time()\n",
    "for j in range(len(catchments)):\n",
    "    catchments[j] = catchments[j][catchments[j][resource_dropdown.value]!=float('inf')]\n",
    "result=overlapping_function(grid_file, catchments, resource_dropdown.value, weights, num_proc=processor_dropdown.value)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = normalization(result, resource_dropdown.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization & Conclusion\n",
    "\n",
    "The black dots represent hospitals. People living in the darker-colored regions are more accessible to the hospitals than those living in the lighter-colored regions. To cope with this health inequality issue, policy makers need to consider about placing more hospitals in the ligher-colored regions. This can also be applicable to COVID-19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DERRICK: Add code to transform to CT State Plane\n",
    "result = result.to_crs({'init': 'epsg:6433'})\n",
    "hospitals=hospitals.to_crs(epsg=6433)\n",
    "pop_data=pop_data.to_crs(epsg=6433)\n",
    "output_map(result, pop_data, hospitals, resource_dropdown.value)\n",
    "# DERRICK: add code to save the output plot\n",
    "# uncomment the below line if you want to save the output (rename)\n",
    "#plt.savefig(\"./CTData/Result/CovidICU.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
